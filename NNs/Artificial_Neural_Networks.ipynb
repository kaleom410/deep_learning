{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "toNodes = range(3, 5)\n",
    "fromNodes = range(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias       = [0.2, -0.1, 0.5, 0.1, 0.4, 0.9]\n",
    "activation = [0.8, -0.3, -0.8, 0.1, 0.5]\n",
    "netInput   = [0, 0, 0, 0, 0]\n",
    "weight = [[ 0.1, -0.8], \n",
    "          [-0.3,  0.1], \n",
    "          [ 0.2, -0.1], \n",
    "          [ 0.0,  0.1], \n",
    "          [ 0.8, -0.8], \n",
    "          [ 0.4, 0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0.07, 1.28]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in toNodes:\n",
    "    netInput[i] = bias[i]\n",
    "    for j in fromNodes:\n",
    "        netInput[i] += (weight[i][j] * activation[j]) \n",
    "netInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `weight[i][j]` is the weight $w_{ij}$, or connection strength, from the $j^{th}$ node to the $i^{th}$ node, `activation[j]` is the activation signal $x_j$ of the $j^{th}$ input node, and `bias[i]` is the bias value $b_i$ of the $i^{th}$ node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing the net input, each node has to compute its output activation. The value that results from applying the activation function to the net input is the signal that will be sent as output to all the nodes in the next layer. The **activation function** used in backprop networks is generally:\n",
    "\n",
    "$$ a_i = \\sigma(net_i) $$\n",
    "\n",
    "where \n",
    "\n",
    "$$ \\sigma(x) = \\dfrac{1}{1 + e^{-x}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method math.exp() returns returns exponential of x: $e^{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activationFunction(netInput):\n",
    "    return 1.0 / (1.0 + math.exp(-netInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the complete activation of a unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8, -0.3, -0.8, 0.5174928576663897, 0.7824497764231124]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in toNodes:\n",
    "    activation[i] = activationFunction(netInput[i])\n",
    "activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This $\\sigma$ is the activation function, as shown in the plot below. Notice that the function is monotonically increasing and bounded by 0.0 and 1.0 as the net input approaches negative infinity and positive infinity, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = range(-10, 10)\n",
    "pts = [activationFunction(x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs, pts)\n",
    "plt.xlabel(\"input\")\n",
    "plt.ylabel(\"output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 How to set the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many years, it was unknown how to learn the weights in a multi-layered neural network. In addition, Marvin Minsky and Seymour Papert proved in their 1969 book [Perceptrons](https://en.wikipedia.org/wiki/Perceptrons_(book)) that you could not do simple functions without having multi-layers. (Actually, the idea of using simulated evolution to search for the weights could have been used, but no one thought to do that.) \n",
    "\n",
    "Specifically, they looked at the function XOR:\n",
    "\n",
    "**Input 1** | **Input 2** | **Target**\n",
    "------------|-------------|-------\n",
    " 0 | 0 | 0\n",
    " 0 | 1 | 1 \n",
    " 1 | 0 | 1 \n",
    " 1 | 1 | 0 \n",
    "\n",
    "This killed research into neural networks for more than a decade. So, the idea of neural networks generally was ignored until the mid 1980s when the **Back-Propagation of Error** (backprop) was created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Learning Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backprop networks fall under the category of *supervised learning* schemes. That is, during training, the network is presented a training input, the inputs are propagated using the transfer function, until output appears in the output layer. The output is then compared with the expected or target output and an error is computed. The error is then backpropagated by applying the learning rule. \n",
    "\n",
    "A learning rule modifies the weights between nodes. The backpropagation algorithm, also called the *generalized delta rule*, systematically changes the weights by using a weight change equation. We use an optional momentum term in the weight change rule to help speed up convergence. The weight change rule is different for weights between the hidden-output layer nodes and the input-hidden layer nodes. For the hidden-output layer nodes it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiredOutput = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "actualOutput = [0.8, 0.6, 0.5, 0.8, 0.3]\n",
    "\n",
    "error = [0.0 for i in desiredOutput]\n",
    "delta = [0.0 for i in desiredOutput]\n",
    "\n",
    "EPSILON = 0.1   # learning rate\n",
    "MOMENTUM = 0.01 # a smoothing term\n",
    "\n",
    "weightUpdate = [[ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0], \n",
    "                [ 0.0, 0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the learning rule applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [-0.005171200000000001, -0.0038784],\n",
       " [0.0033936, 0.0025451999999999996],\n",
       " [0.0, 0.0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in toNodes:\n",
    "    error[i] = (desiredOutput[i] - actualOutput[i])\n",
    "    delta[i] = error[i] * actualOutput[i] * (1 - actualOutput[i])\n",
    "    for j in fromNodes:\n",
    "        weightUpdate[i][j] = (EPSILON * delta[i] * actualOutput[j]) + (MOMENTUM * weightUpdate[i][j])\n",
    "        \n",
    "weightUpdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, at the $i^{th}$ output node, the error is the difference between desired and actual outputs. The weight change between a hidden layer node $j$ and output node $i$ --- `weightUpdate[i][j]` --- is a fraction of the computed delta value and additionally a fraction of the weight change from the previous training step. MOMENTUM is a constant that ranges between 0.0 and 1.0 and **EPSILON** is called the **learning rate** and is also a constant that varies between 0.0 and 1.0.\n",
    "\n",
    "In the above code `delta[i] * actualOutput[j]` is the partial derivative of the overall error with respect to each weight. This is the slope of error. Thus, backprop changes the weight a tiny portion of the slope of the error. We only know the slope of this curve, not the shape, and thus have to take very small steps.\n",
    "\n",
    "And that is all of the math, and Python, necessary to train a back-propagation of error neural network. Even though this is a very simple formulation, it has been proved that such three-layer network (input, hidden, output) is capable of computing any function that can be computed (Franklin and Garzon).\n",
    "\n",
    "\n",
    "To make coding these networks easier (and faster, using matrix multiplication) we have created a Python library called `conx`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a task, how does one train a neural network to do/solve the task? This involves the following steps:\n",
    "\n",
    " 1. Determine an appropriate network architecture.\n",
    " 1. Define a data set that will be used for training.\n",
    " 1. Define the neural network parameters to be used for training.\n",
    " 1. Train the network.\n",
    " 1. Test the trained network.\n",
    " 1. Do post training analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1 Determining an appropriate architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a neural network consists of an input layer, an output layer, and zero or more hidden layers. Once a network has been trained, when you present an input to the network, the network will propagate the inputs through its layers to produce an output (using the transfer function described above). If the input represents an instance of the task, the output should be the solution to that instance after the network has been trained. Thus, one can view a neural network as a general pattern associator. Thus, given a task, the first step is to identify the nature of inputs to the pattern associator. This is normally in the form of number of nodes required to represent the input. Similarly, you will need to determine how many output nodes will be required. For example, consider a simple logical connective, AND whose input-output characteristics are summarized in the table below:\n",
    "\n",
    "**Input A** | **Input B** | **Target**\n",
    "------------|-------------|-------\n",
    " 0 | 0 | 0\n",
    " 0 | 1 | 0 \n",
    " 1 | 0 | 0 \n",
    " 1 | 1 | 1 \n",
    "\n",
    "This is a very simple example, but it will help us illustrate all of the important concepts in defining and training neural networks.\n",
    "\n",
    "In this example, it is clear that we will need two nodes in the input layer, and one in the output layer. We can start by assuming that we will not need a hidden layer. In general, as far as the design of a neural network is concerned, you always begin by identifying the size of the input and output layers. Then, you decide how many hidden layers you would use. In most situations you will need one hidden layer, though there are no hard and fast rules about its size. Through much empirical practice, you will develop your own heuristics about this. We will return to this issue later. In the case of the AND network, it is simple enough that we have decided not to use any hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2 Define a data set that will be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have decided on the network architecture, you have to prepare the data set that will be used for training. Each item in the data set represents an input pattern and the correct output pattern that should be produced by the network (since this is supervised training). In most tasks, there can be an infinite number of such input-output associations. Obviously it would be impossible to enumerate all associations for all tasks (and it would make little sense to even try to do this!). You have to then decide what comprises a good representative data set that, when used in training a network, would generalize to all situations.\n",
    "\n",
    "In the case of the AND network, the data set is very small, finite (only 4 cases!), and exhaustive.\n",
    "\n",
    "The other issue you have to take into consideration here is that of the range of each input and output value. Remember the transfer function of a node is a sigmoid-function that serves to squash all input values between 0.0 and 1.0. Thus, regardless of the size of each input value into a node, the output produced by each node is between 0.0 and 1.0. This means that all output nodes have values in that range. If the task you are dealing with expects outputs between 0.0 and 1.0, then there is nothing to worry about. However, in most situations, you will need to *scale* the output values back to the values in the task domain. \n",
    "\n",
    "In reality, it is also a good idea to scale the input values from the domain into the 0.0 to 1.0 range (especially if most input values are outside the -5.0 and 5.0 range). Thus, defining a data set for training almost always requires a collection of input-output pairs, as well as scaling and unscaling operations. Luckily, for the AND task, we do not need to do any scaling, but we will see several examples of this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.3 Define the neural network parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define the parameters required to train the neural network. These include the following:\n",
    "\n",
    " 1. The learning constant\n",
    " 1. The momentum constant\n",
    " 1. The tolerance\n",
    " 1. Other training-related parameters\n",
    "\n",
    "The learning rate, EPSILON, and the momentum constant, MOMENTUM, have to be between 0.0 and 1.0 and are critical to the overall training algorithm. The appropriate values of these constants are best determined by experimentation. Tolerance (which is also between 0.0 and 1.0) refers to the level of tolerance that is acceptable for determining correctness of the output. For example, if tolerance is set to 0.1, then an output value within 10% of the desired output is considered correct. Other training parameters generally exist to specify the reporting rate of the progress of the training, where to log such progress, etc. We will see specific examples of these as we start working with actual networks.\n",
    "\n",
    "For the AND network, we will set EPSILON to 0.5, MOMENTUM to 0.0, report the progress every 5 epochs (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.4 Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the parameters are specified, you start the training process. This involves presenting each input pattern to the network, propagating it all the way until an output is produced, comparing the output with the desired target, computing the error, backpropagating the error, and applying the learning rule.  This process is repeated  until all inputs are exhausted. A single pass through an entire data set is called an *epoch*. In general, you always train the network for several epochs (can be anywhere from a few hundred to millions!) until the network begins to show more improved and stable performance. Performance of the network is generally measured in terms of the *total sum-squared error* or *TSS* for short. This is the error in each pattern squared and summed over all the patterns. Initially, you will notice that the TSS is quite high, but it will slowly decrease as the number of epochs increase. \n",
    "\n",
    "You can either stop the training process after a certain number of epochs have elapsed, or after the TSS has decreased to a specific amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.5 Test the trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network has been trained, it is time to test it. There are several ways of doing this. Perhaps the easiest is to turn learning off (another training parameter) and then see the outputs produced by the network for each input in the data set. When a trained network is going to be used in a *deployed* application, all you have to do is save the weights of all interconnections in the network into a file. The trained network can then be recreated at anytime by reloading the weights.\n",
    "\n",
    "Note: Instead of training-then-testing, there is another methodology: you can test-while-training. Conx's neural network system supports the idea of **cross validation**. With cross validation one defines a training corpus and testing corpus at the beginning. Occasionally, as training proceeds on the training corpus, the system will stop training momentarily (by turning learning off) and test its current weights on the test corpus. This methodology has the advantage of being able to stop when performance on the test corpus begins to drop, thereby preventing over-training. See [Conx Implementation Details]() for more details on cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.6 Do post training analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most important step in using neural networks is the analysis one performs once a network has been trained. There are a whole host of analysis techniques, we will present some of them as we go along.\n",
    "\n",
    "Next, we will introduce you to the Python package called, `conx` that is used to create and experiment with neural networks. We will use the AND network example from this section to learn about conx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learning AND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the AND function:\n",
    "\n",
    "**Input A** | **Input B** | **Target**\n",
    "------------|-------------|-------\n",
    " 0 | 0 | 0\n",
    " 0 | 1 | 0 \n",
    " 1 | 0 | 0 \n",
    " 1 | 1 | 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import all of the items from the `conx` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calysto.ai.conx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AND experiment, we will create a 2-3-1 network:\n",
    "\n",
    "* input layer of two units\n",
    "* hidden layer of three (arbitrary, but not too big)\n",
    "* output layer of one unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conx using seed: 1649792371.2378194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Layer 'output': (Kind: Output, Size: 1, Active: 1, Frozen: 0)\n",
       "Target    : 0.00  \n",
       "Activation: 0.00  \n",
       "Layer 'hidden': (Kind: Hidden, Size: 3, Active: 1, Frozen: 0)\n",
       "Activation: 0.00  0.00  0.00  \n",
       "Layer 'input': (Kind: Input, Size: 2, Active: 1, Frozen: 0)\n",
       "Activation: 0.00  0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network()\n",
    "net.addLayers(2, 3, 1)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can propagate activation through the network (from input layer, through the hidden layer, to output layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('d', [0.4932597949390636])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(input=[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how an untrained network works on the AND problem, we can just propagate the input activations for each input pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] array('d', [0.4932597949390636])\n",
      "[0, 1] array('d', [0.49297150210742524])\n",
      "[1, 0] array('d', [0.4934311067623621])\n",
      "[1, 1] array('d', [0.493142975568295])\n"
     ]
    }
   ],
   "source": [
    "for pattern in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n",
    "    print(pattern, net.propagate(input=pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train a network to determine the weights to compute the AND function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #     1 | TSS Error: 1.0489 | Correct: 0.0000 | RMS Error: 0.5121\n",
      "Epoch #     2 | TSS Error: 1.0271 | Correct: 0.0000 | RMS Error: 0.5067\n",
      "Epoch #     3 | TSS Error: 0.8033 | Correct: 0.7500 | RMS Error: 0.4481\n",
      "Epoch #     4 | TSS Error: 0.8614 | Correct: 0.7500 | RMS Error: 0.4641\n",
      "Epoch #     5 | TSS Error: 0.8613 | Correct: 0.7500 | RMS Error: 0.4640\n",
      "Epoch #     6 | TSS Error: 0.7501 | Correct: 0.7500 | RMS Error: 0.4330\n",
      "Epoch #     7 | TSS Error: 0.7534 | Correct: 0.2500 | RMS Error: 0.4340\n",
      "Epoch #     8 | TSS Error: 0.6998 | Correct: 0.0000 | RMS Error: 0.4183\n",
      "Epoch #     9 | TSS Error: 0.7015 | Correct: 0.0000 | RMS Error: 0.4188\n",
      "Epoch #    10 | TSS Error: 0.7163 | Correct: 0.0000 | RMS Error: 0.4232\n",
      "Epoch #    11 | TSS Error: 0.7061 | Correct: 0.0000 | RMS Error: 0.4202\n",
      "Epoch #    12 | TSS Error: 0.6801 | Correct: 0.2500 | RMS Error: 0.4123\n",
      "Epoch #    13 | TSS Error: 0.6392 | Correct: 0.2500 | RMS Error: 0.3997\n",
      "Epoch #    14 | TSS Error: 0.5958 | Correct: 0.2500 | RMS Error: 0.3859\n",
      "Epoch #    15 | TSS Error: 0.5942 | Correct: 0.2500 | RMS Error: 0.3854\n",
      "Epoch #    16 | TSS Error: 0.5936 | Correct: 0.2500 | RMS Error: 0.3852\n",
      "Epoch #    17 | TSS Error: 0.5618 | Correct: 0.2500 | RMS Error: 0.3748\n",
      "Epoch #    18 | TSS Error: 0.5591 | Correct: 0.2500 | RMS Error: 0.3739\n",
      "Epoch #    19 | TSS Error: 0.4993 | Correct: 0.5000 | RMS Error: 0.3533\n",
      "Epoch #    20 | TSS Error: 0.4880 | Correct: 0.5000 | RMS Error: 0.3493\n",
      "Epoch #    21 | TSS Error: 0.3998 | Correct: 0.2500 | RMS Error: 0.3161\n",
      "Epoch #    22 | TSS Error: 0.3653 | Correct: 0.2500 | RMS Error: 0.3022\n",
      "Epoch #    23 | TSS Error: 0.3450 | Correct: 0.2500 | RMS Error: 0.2937\n",
      "Epoch #    24 | TSS Error: 0.3226 | Correct: 0.2500 | RMS Error: 0.2840\n",
      "Epoch #    25 | TSS Error: 0.2850 | Correct: 0.2500 | RMS Error: 0.2669\n",
      "Epoch #    26 | TSS Error: 0.2157 | Correct: 0.5000 | RMS Error: 0.2322\n",
      "Epoch #    27 | TSS Error: 0.1898 | Correct: 0.7500 | RMS Error: 0.2178\n",
      "Epoch #    28 | TSS Error: 0.1579 | Correct: 0.7500 | RMS Error: 0.1987\n",
      "Epoch #    29 | TSS Error: 0.1364 | Correct: 0.7500 | RMS Error: 0.1847\n",
      "Epoch #    30 | TSS Error: 0.1130 | Correct: 0.7500 | RMS Error: 0.1680\n",
      "Epoch #    31 | TSS Error: 0.0976 | Correct: 0.7500 | RMS Error: 0.1562\n",
      "Epoch #    32 | TSS Error: 0.0793 | Correct: 0.7500 | RMS Error: 0.1408\n",
      "Epoch #    33 | TSS Error: 0.0748 | Correct: 0.7500 | RMS Error: 0.1368\n",
      "Epoch #    34 | TSS Error: 0.0602 | Correct: 0.7500 | RMS Error: 0.1227\n",
      "Epoch #    35 | TSS Error: 0.0514 | Correct: 0.7500 | RMS Error: 0.1133\n",
      "Epoch #    36 | TSS Error: 0.0474 | Correct: 1.0000 | RMS Error: 0.1088\n",
      "Final #    36 | TSS Error: 0.0474 | Correct: 1.0000 | RMS Error: 0.1088\n"
     ]
    }
   ],
   "source": [
    "# provide training patterns (inputs and outputs)\n",
    "net.setInputs([[0.0, 0.0],[0.0, 1.0],[1.0, 0.0],[1.0, 1.0]])\n",
    "net.setOutputs([[0.0],[0.0],[0.0],[1.0]])\n",
    "\n",
    "# set learning parameters\n",
    "net.setEpsilon(0.5)\n",
    "net.setTolerance(0.2)\n",
    "net.setReportRate(1)\n",
    "\n",
    "# learn\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be pretty easy to learn this function, taking around 10 to 20 cycles through the 4 training patterns (called an **epoch**). We can test each input pattern to see if it really works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] array('d', [0.0004404983243821034])\n",
      "[0, 1] array('d', [0.10400586790703523])\n",
      "[1, 0] array('d', [0.08549461967851019])\n",
      "[1, 1] array('d', [0.8577884508536319])\n"
     ]
    }
   ],
   "source": [
    "for pattern in [[0, 0], [0, 1], [1, 0], [1, 1]]:\n",
    "    print(pattern, net.propagate(input=pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! It really works. But it gets even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great side benefits of using a neural network to solve a problem is that it can also do slightly different problems that it was not trained on.\n",
    "\n",
    "For example, we didn't explicitly train the network on [0.8, 0.8] for the AND problem, but we can see what the network thinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('d', [0.7205753811234459])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.propagate(input=[0.8, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a reasonable answer. To see all of the reasonable answers, we can sample the entire input space for the two input units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.zeros((100, 100))\n",
    "\n",
    "for x in range(100):\n",
    "    for y in range(100):\n",
    "        z[x][y] = net.propagate(input=[x/100, y/100])[0]\n",
    "\n",
    "plt.imshow(z, cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.xlabel(\"input 1\")\n",
    "plt.ylabel(\"input 2\")\n",
    "plt.title(\"Output Activation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
